{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:44:33.086800Z",
     "iopub.status.busy": "2021-12-12T23:44:33.086090Z",
     "iopub.status.idle": "2021-12-12T23:44:39.655717Z",
     "shell.execute_reply": "2021-12-12T23:44:39.654732Z",
     "shell.execute_reply.started": "2021-12-12T23:44:33.086694Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 4\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras import Model, losses, optimizers\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from kaggle_datasets import KaggleDatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data into variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:44:45.417542Z",
     "iopub.status.busy": "2021-12-12T23:44:45.417189Z",
     "iopub.status.idle": "2021-12-12T23:44:46.201256Z",
     "shell.execute_reply": "2021-12-12T23:44:46.200502Z",
     "shell.execute_reply.started": "2021-12-12T23:44:45.417490Z"
    }
   },
   "outputs": [],
   "source": [
    "GCS_PATH = KaggleDatasets().get_gcs_path('gan-getting-started')\n",
    "\n",
    "monets_tfr = tf.io.gfile.glob(str(GCS_PATH + '/monet_tfrec/*.tfrec'))\n",
    "photos_tfr = tf.io.gfile.glob(str(GCS_PATH + '/photo_tfrec/*.tfrec'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the records and files used in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:44:46.203033Z",
     "iopub.status.busy": "2021-12-12T23:44:46.202567Z",
     "iopub.status.idle": "2021-12-12T23:44:46.214332Z",
     "shell.execute_reply": "2021-12-12T23:44:46.213570Z",
     "shell.execute_reply.started": "2021-12-12T23:44:46.203001Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "monet_jpg = count_data_items(monets_tfr)\n",
    "photo_jpg = count_data_items(photos_tfr)\n",
    "\n",
    "EPOCHS = 30\n",
    "\n",
    "print(\"Monet TFRecord files:\", len(monets_tfr))\n",
    "print(\"Monet image files:\", monet_jpg)\n",
    "print(\"Photo TFRecord files:\", len(photos_tfr))\n",
    "print(\"Photo image files:\", photo_jpg)\n",
    "print(\"EPOCHS:\",EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the Image Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:44:46.217811Z",
     "iopub.status.busy": "2021-12-12T23:44:46.216863Z",
     "iopub.status.idle": "2021-12-12T23:44:46.222369Z",
     "shell.execute_reply": "2021-12-12T23:44:46.221400Z",
     "shell.execute_reply.started": "2021-12-12T23:44:46.217775Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [256, 256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:44:46.223797Z",
     "iopub.status.busy": "2021-12-12T23:44:46.223351Z",
     "iopub.status.idle": "2021-12-12T23:44:46.234150Z",
     "shell.execute_reply": "2021-12-12T23:44:46.232809Z",
     "shell.execute_reply.started": "2021-12-12T23:44:46.223756Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = (tf.cast(image, tf.float32) / 127.5) - 1\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the TFRecord files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:44:46.237521Z",
     "iopub.status.busy": "2021-12-12T23:44:46.236356Z",
     "iopub.status.idle": "2021-12-12T23:44:46.245502Z",
     "shell.execute_reply": "2021-12-12T23:44:46.244560Z",
     "shell.execute_reply.started": "2021-12-12T23:44:46.237467Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_tfrecord(example):\n",
    "    tfrecord_format = {\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    image = decode_image(example['image'])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random jittering and mirroring to the training dataset. These are some of the image augmentation techniques that avoids overfitting, Random jittering performs:\n",
    "\n",
    "Resize an image to bigger height and width\n",
    "Randomly crop to the target size\n",
    "Randomly rotate the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:44:46.246995Z",
     "iopub.status.busy": "2021-12-12T23:44:46.246712Z",
     "iopub.status.idle": "2021-12-12T23:44:46.263082Z",
     "shell.execute_reply": "2021-12-12T23:44:46.261931Z",
     "shell.execute_reply.started": "2021-12-12T23:44:46.246957Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_augment(image):\n",
    "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    if p_crop > .5:\n",
    "        image = tf.image.resize(image, [286, 286]) #resizing to 286 x 286 x 3\n",
    "        image = tf.image.random_crop(image, size=[256, 256, 3]) # randomly cropping to 256 x 256 x 3\n",
    "        if p_crop > .9:\n",
    "            image = tf.image.resize(image, [300, 300])\n",
    "            image = tf.image.random_crop(image, size=[256, 256, 3])\n",
    "    \n",
    "    if p_rotate > .9:\n",
    "        image = tf.image.rot90(image, k=3) # rotate 270ยบ\n",
    "    elif p_rotate > .7:\n",
    "        image = tf.image.rot90(image, k=2) # rotate 180ยบ\n",
    "    elif p_rotate > .5:\n",
    "        image = tf.image.rot90(image, k=1) # rotate 90ยบ\n",
    "        \n",
    "        ## random mirroring\n",
    "    if p_spatial > .6:\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_flip_up_down(image)\n",
    "        if p_spatial > .9:\n",
    "            image = tf.image.transpose(image)\n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:44:46.265062Z",
     "iopub.status.busy": "2021-12-12T23:44:46.264582Z",
     "iopub.status.idle": "2021-12-12T23:44:46.276056Z",
     "shell.execute_reply": "2021-12-12T23:44:46.274981Z",
     "shell.execute_reply.started": "2021-12-12T23:44:46.265030Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(filenames):\n",
    "    data = tf.data.TFRecordDataset(filenames)\n",
    "    data = data.map(read_tfrecord, num_parallel_calls=AUTO_TUNE)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the GAN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:44:46.278338Z",
     "iopub.status.busy": "2021-12-12T23:44:46.277563Z",
     "iopub.status.idle": "2021-12-12T23:44:47.573520Z",
     "shell.execute_reply": "2021-12-12T23:44:47.572362Z",
     "shell.execute_reply.started": "2021-12-12T23:44:46.278270Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_gan_dataset(monet_files, photo_files, augment=None, repeat=True, shuffle=True, batch_size=1):\n",
    "\n",
    "    monet_ds = load_dataset(monet_files)\n",
    "    photo_ds = load_dataset(photo_files)\n",
    "    \n",
    "    if augment:\n",
    "        monet_ds = monet_ds.map(augment, num_parallel_calls=AUTO_TUNE)\n",
    "        photo_ds = photo_ds.map(augment, num_parallel_calls=AUTO_TUNE)\n",
    "        \n",
    "    if repeat:\n",
    "        monet_ds = monet_ds.repeat()\n",
    "        photo_ds = photo_ds.repeat()\n",
    "    if shuffle:\n",
    "        monet_ds = monet_ds.shuffle(2048)\n",
    "        photo_ds = photo_ds.shuffle(2048)\n",
    "        \n",
    "    monet_ds = monet_ds.batch(batch_size, drop_remainder=True)\n",
    "    photo_ds = photo_ds.batch(batch_size, drop_remainder=True)\n",
    "    monet_ds = monet_ds.cache()\n",
    "    photo_ds = photo_ds.cache()\n",
    "    monet_ds = monet_ds.prefetch(AUTO_TUNE)\n",
    "    photo_ds = photo_ds.prefetch(AUTO_TUNE)\n",
    "    \n",
    "    gan_ds = tf.data.Dataset.zip((monet_ds, photo_ds))\n",
    "    \n",
    "    return gan_ds\n",
    "\n",
    "data = get_gan_dataset(monets_tfr, photos_tfr, augment=data_augment, repeat=True, shuffle=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the data and checking that the upload is successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:44:47.575019Z",
     "iopub.status.busy": "2021-12-12T23:44:47.574779Z",
     "iopub.status.idle": "2021-12-12T23:44:52.507888Z",
     "shell.execute_reply": "2021-12-12T23:44:52.506810Z",
     "shell.execute_reply.started": "2021-12-12T23:44:47.574992Z"
    }
   },
   "outputs": [],
   "source": [
    "example_monet , example_photo = next(iter(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:44:52.510030Z",
     "iopub.status.busy": "2021-12-12T23:44:52.509648Z",
     "iopub.status.idle": "2021-12-12T23:44:53.428071Z",
     "shell.execute_reply": "2021-12-12T23:44:53.427296Z",
     "shell.execute_reply.started": "2021-12-12T23:44:52.509984Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualizing the real photo\n",
    "plt.subplot(121)\n",
    "plt.title('Real photo')\n",
    "plt.imshow(example_photo[2] * 0.5 + 0.5)\n",
    "\n",
    "# Visualizing the Monet painting\n",
    "plt.subplot(122)\n",
    "plt.title('Monet painting')\n",
    "plt.imshow(example_monet[2]* 0.5 + 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:44:53.429721Z",
     "iopub.status.busy": "2021-12-12T23:44:53.429180Z",
     "iopub.status.idle": "2021-12-12T23:44:53.437186Z",
     "shell.execute_reply": "2021-12-12T23:44:53.435414Z",
     "shell.execute_reply.started": "2021-12-12T23:44:53.429683Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_samples(dataset, nrows, ncols):\n",
    "    ds_iter = iter(dataset)\n",
    "    plt.figure(figsize=(15, int(15*nrows/ncols)))\n",
    "    for j in range(nrows*ncols):\n",
    "        monet_sample = next(ds_iter)\n",
    "        plt.subplot(nrows,ncols,j+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(monet_sample[0] * 0.5 + 0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:44:53.441686Z",
     "iopub.status.busy": "2021-12-12T23:44:53.441364Z",
     "iopub.status.idle": "2021-12-12T23:44:55.428648Z",
     "shell.execute_reply": "2021-12-12T23:44:55.427637Z",
     "shell.execute_reply.started": "2021-12-12T23:44:53.441654Z"
    }
   },
   "outputs": [],
   "source": [
    "display_samples(load_dataset(monets_tfr).batch(1), 5, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL\n",
    "\n",
    "To build the model, we will follow the following steps:\n",
    "\n",
    "* Build the Generator\n",
    "* Build the Discriminador\n",
    "* Loss functions -\n",
    "         Discriminator loss,\n",
    "         Generator loss,\n",
    "         Adversary loss,\n",
    "         Cycle loss\n",
    "* Identity loss\n",
    "Define the optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsampling the images for Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:44:55.430362Z",
     "iopub.status.busy": "2021-12-12T23:44:55.430068Z",
     "iopub.status.idle": "2021-12-12T23:44:55.440067Z",
     "shell.execute_reply": "2021-12-12T23:44:55.438825Z",
     "shell.execute_reply.started": "2021-12-12T23:44:55.430326Z"
    }
   },
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_instancenorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.04)\n",
    "    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "\n",
    "     \n",
    "    result = keras.Sequential()\n",
    "    # Convolutional layer\n",
    "    result.add(layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    " # Normalization layer\n",
    "    if apply_instancenorm:\n",
    "        result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n",
    " # Activation layer\n",
    "    result.add(layers.LeakyReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsampling the images for Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:44:55.442870Z",
     "iopub.status.busy": "2021-12-12T23:44:55.442518Z",
     "iopub.status.idle": "2021-12-12T23:44:55.466175Z",
     "shell.execute_reply": "2021-12-12T23:44:55.465013Z",
     "shell.execute_reply.started": "2021-12-12T23:44:55.442831Z"
    }
   },
   "outputs": [],
   "source": [
    "def upsample(filters, size, apply_dropout=False):\n",
    "     # Normalization layer\n",
    "    initializer = tf.random_normal_initializer(0., 0.04)\n",
    "    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "\n",
    "     # Transpose convolutional layer\n",
    "    result = keras.Sequential()\n",
    "    result.add(layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                      padding='same',\n",
    "                                      kernel_initializer=initializer,\n",
    "                                      use_bias=False))\n",
    "#Instance Normalization\n",
    "    result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n",
    "# Dropout layer\n",
    "    if apply_dropout:\n",
    "        result.add(layers.Dropout(0.5))\n",
    "# Activation layer\n",
    "    result.add(layers.ReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator -\n",
    "\n",
    "The architecture of the generator is a modified U-Net, consisting of an encoder block and a decoder block, each of them is made up of simpler blocks of layers: Each block of the encoder, we call it downsample-k where k denotes the number of filters, consisting of the following layers:\n",
    "\n",
    "* Convolution\n",
    "* Instance Normalization \n",
    "* Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:44:55.468358Z",
     "iopub.status.busy": "2021-12-12T23:44:55.467443Z",
     "iopub.status.idle": "2021-12-12T23:44:55.483894Z",
     "shell.execute_reply": "2021-12-12T23:44:55.482968Z",
     "shell.execute_reply.started": "2021-12-12T23:44:55.468288Z"
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "def Generator_PM():\n",
    "    data = layers.Input(shape=[256,256,3])\n",
    "\n",
    "    # bs = batch size\n",
    "    down_sample = [\n",
    "        downsample(64, 4, apply_instancenorm=False), # (bs, 128, 128, 64)\n",
    "        downsample(128, 4), # (bs, 64, 64, 128)\n",
    "        downsample(256, 4), # (bs, 32, 32, 256)\n",
    "        downsample(512, 4), # (bs, 16, 16, 512)\n",
    "        downsample(512, 4), # (bs, 8, 8, 512)\n",
    "        downsample(512, 4), # (bs, 4, 4, 512)\n",
    "        downsample(512, 4), # (bs, 2, 2, 512)\n",
    "        downsample(512, 4), # (bs, 1, 1, 512)\n",
    "    ]\n",
    "\n",
    "    up_sample = [\n",
    "        upsample(512, 4, apply_dropout=True), \n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n",
    "        upsample(512, 4), # (bs, 16, 16, 1024)\n",
    "        upsample(256, 4), # (bs, 32, 32, 512)\n",
    "        upsample(128, 4), # (bs, 64, 64, 256)\n",
    "        upsample(64, 4), # (bs, 128, 128, 128)\n",
    "    ]\n",
    "    \n",
    "    initialize = tf.random_normal_initializer(0., 0.02)\n",
    "    final = layers.Conv2DTranspose(3, 7,\n",
    "                                  strides=2,\n",
    "                                  padding='same',\n",
    "                                  kernel_initializer=initialize,\n",
    "                                  activation='tanh') # (bs, 256, 256, 3)\n",
    "\n",
    "    inputs = data\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skip_connection = []\n",
    "    for down in down_sample:\n",
    "        inputs = down(inputs)\n",
    "        skip_connection.append(inputs)\n",
    "        \n",
    "    skip_connection = reversed(skip_connection[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_sample, skip_connection):\n",
    "        inputs = up(inputs)\n",
    "        inputs = layers.Concatenate()([inputs, skip])\n",
    "\n",
    "    inputs = final(inputs)\n",
    "\n",
    "    return keras.Model(inputs=data, outputs=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:44:55.486015Z",
     "iopub.status.busy": "2021-12-12T23:44:55.485193Z",
     "iopub.status.idle": "2021-12-12T23:44:58.984678Z",
     "shell.execute_reply": "2021-12-12T23:44:58.983523Z",
     "shell.execute_reply.started": "2021-12-12T23:44:55.485977Z"
    }
   },
   "outputs": [],
   "source": [
    "generator = Generator_PM()\n",
    "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator - \n",
    "\n",
    "The task of the discriminator is whether an input image, which is (the output of a generator), is original or fake!\n",
    "It can be seen that the architecture of the discriminator is a convolution network of the PatchGAN type, instead of returning whether the image is real or not, this architecture returns whether pieces of the image can be considered real or false. As we mentioned in the generator, the encoder is made up of downsample-k blocks, the block performs an image compression operation (downsample). It consists of the following layers:\n",
    "\n",
    "* Convolution\n",
    "* Instance Normalization \n",
    "* Leaky ReLU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:44:58.986672Z",
     "iopub.status.busy": "2021-12-12T23:44:58.986379Z",
     "iopub.status.idle": "2021-12-12T23:44:59.000885Z",
     "shell.execute_reply": "2021-12-12T23:44:58.998953Z",
     "shell.execute_reply.started": "2021-12-12T23:44:58.986638Z"
    }
   },
   "outputs": [],
   "source": [
    "def Discriminator_PM():\n",
    "    initialize = tf.random_normal_initializer(0., 0.02)\n",
    "    init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "\n",
    "    data = layers.Input(shape=[256, 256, 3], name='input_image')\n",
    "\n",
    "    inputs = data\n",
    "\n",
    "    down1 = downsample(64, 4, False)(inputs) # (bs, 128, 128, 64)\n",
    "    down2 = downsample(128, 4)(down1) # (bs, 64, 64, 128)\n",
    "    down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\n",
    "\n",
    "    zero_pad1 = layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
    "    conv = layers.Conv2D(512, 7, strides=2,\n",
    "                         kernel_initializer=initialize,\n",
    "                         use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
    "\n",
    "    norm1 = tfa.layers.InstanceNormalization(gamma_initializer=init)(conv)\n",
    "\n",
    "    leaky_relu = layers.LeakyReLU()(norm1)\n",
    "    \n",
    "    zero_pad2 = layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
    "\n",
    "    final = layers.Conv2D(1, 7, strides=2,\n",
    "                         kernel_initializer=initialize)(zero_pad2) # (bs, 30, 30, 1)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:44:59.003141Z",
     "iopub.status.busy": "2021-12-12T23:44:59.002428Z",
     "iopub.status.idle": "2021-12-12T23:44:59.438907Z",
     "shell.execute_reply": "2021-12-12T23:44:59.437856Z",
     "shell.execute_reply.started": "2021-12-12T23:44:59.003101Z"
    }
   },
   "outputs": [],
   "source": [
    "discriminator_y = Discriminator_PM()\n",
    "tf.keras.utils.plot_model(discriminator_y, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:44:59.440881Z",
     "iopub.status.busy": "2021-12-12T23:44:59.440581Z",
     "iopub.status.idle": "2021-12-12T23:45:09.507440Z",
     "shell.execute_reply": "2021-12-12T23:45:09.506337Z",
     "shell.execute_reply.started": "2021-12-12T23:44:59.440847Z"
    }
   },
   "outputs": [],
   "source": [
    "with tpu_strategy.scope():\n",
    "    monet_generator = Generator_PM() # transforms photos to Monet-esque paintings\n",
    "    photo_generator = Generator_PM() # transforms Monet paintings to be more like photos\n",
    "\n",
    "    monet_discriminator = Discriminator_PM() # differentiates real Monet paintings and generated Monet paintings\n",
    "    photo_discriminator = Discriminator_PM() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing CycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:45:09.509648Z",
     "iopub.status.busy": "2021-12-12T23:45:09.509267Z",
     "iopub.status.idle": "2021-12-12T23:45:09.537336Z",
     "shell.execute_reply": "2021-12-12T23:45:09.535719Z",
     "shell.execute_reply.started": "2021-12-12T23:45:09.509606Z"
    }
   },
   "outputs": [],
   "source": [
    "class CycleGan(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        monet_generator,\n",
    "        photo_generator,\n",
    "        monet_discriminator,\n",
    "        photo_discriminator,\n",
    "        lambda_cycle=20,\n",
    "    ):\n",
    "        super(CycleGan, self).__init__()\n",
    "        self.m_gen = monet_generator\n",
    "        self.p_gen = photo_generator\n",
    "        self.m_disc = monet_discriminator\n",
    "        self.p_disc = photo_discriminator\n",
    "        self.lambda_cycle = lambda_cycle\n",
    "        \n",
    "    def compile(\n",
    "        self,\n",
    "        m_gen_optimizer,\n",
    "        p_gen_optimizer,\n",
    "        m_disc_optimizer,\n",
    "        p_disc_optimizer,\n",
    "        gen_loss_fn,\n",
    "        disc_loss_fn,\n",
    "        cycle_loss_fn,\n",
    "        identity_loss_fn\n",
    "    ):\n",
    "        super(CycleGan, self).compile()\n",
    "        self.m_gen_optimizer = m_gen_optimizer\n",
    "        self.p_gen_optimizer = p_gen_optimizer\n",
    "        self.m_disc_optimizer = m_disc_optimizer\n",
    "        self.p_disc_optimizer = p_disc_optimizer\n",
    "        self.gen_loss_fn = gen_loss_fn\n",
    "        self.disc_loss_fn = disc_loss_fn\n",
    "        self.cycle_loss_fn = cycle_loss_fn\n",
    "        self.identity_loss_fn = identity_loss_fn\n",
    "        \n",
    "    def train_step(self, batch_data):\n",
    "        real_monet, real_photo = batch_data\n",
    "        \n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # photo to monet back to photo\n",
    "            fake_monet = self.m_gen(real_photo, training=True)\n",
    "            cycled_photo = self.p_gen(fake_monet, training=True)\n",
    "\n",
    "            # monet to photo back to monet\n",
    "            fake_photo = self.p_gen(real_monet, training=True)\n",
    "            cycled_monet = self.m_gen(fake_photo, training=True)\n",
    "\n",
    "            # generating itself\n",
    "            same_monet = self.m_gen(real_monet, training=True)\n",
    "            same_photo = self.p_gen(real_photo, training=True)\n",
    "\n",
    "            # discriminator used to check, inputing real images\n",
    "            disc_real_monet = self.m_disc(real_monet, training=True)\n",
    "            disc_real_photo = self.p_disc(real_photo, training=True)\n",
    "\n",
    "            # discriminator used to check, inputing fake images\n",
    "            disc_fake_monet = self.m_disc(fake_monet, training=True)\n",
    "            disc_fake_photo = self.p_disc(fake_photo, training=True)\n",
    "            \n",
    "             # evaluates generator loss\n",
    "            monet_gen_loss = self.gen_loss_fn(disc_fake_monet)\n",
    "            photo_gen_loss = self.gen_loss_fn(disc_fake_photo)\n",
    "\n",
    "            # evaluates total cycle consistency loss\n",
    "            total_cycle_loss = self.cycle_loss_fn(real_monet, cycled_monet, self.lambda_cycle) + self.cycle_loss_fn(real_photo, cycled_photo, self.lambda_cycle)\n",
    "\n",
    "            # evaluates total generator loss\n",
    "            total_monet_gen_loss = monet_gen_loss + total_cycle_loss + self.identity_loss_fn(real_monet, same_monet, self.lambda_cycle)\n",
    "            total_photo_gen_loss = photo_gen_loss + total_cycle_loss + self.identity_loss_fn(real_photo, same_photo, self.lambda_cycle)\n",
    "\n",
    "            # evaluates discriminator loss\n",
    "            monet_disc_loss = self.disc_loss_fn(disc_real_monet, disc_fake_monet)\n",
    "            photo_disc_loss = self.disc_loss_fn(disc_real_photo, disc_fake_photo)\n",
    "\n",
    "        # Calculate the gradients for generator and discriminator\n",
    "        monet_generator_gradients = tape.gradient(total_monet_gen_loss,\n",
    "                                                  self.m_gen.trainable_variables)\n",
    "        photo_generator_gradients = tape.gradient(total_photo_gen_loss,\n",
    "                                                  self.p_gen.trainable_variables)\n",
    "        \n",
    "        monet_discriminator_gradients = tape.gradient(monet_disc_loss,\n",
    "                                                      self.m_disc.trainable_variables)\n",
    "        photo_discriminator_gradients = tape.gradient(photo_disc_loss,\n",
    "                                                      self.p_disc.trainable_variables)\n",
    "\n",
    "        # Apply the gradients to the optimizer\n",
    "        self.m_gen_optimizer.apply_gradients(zip(monet_generator_gradients,\n",
    "                                                 self.m_gen.trainable_variables))\n",
    "\n",
    "        self.p_gen_optimizer.apply_gradients(zip(photo_generator_gradients,\n",
    "                                                 self.p_gen.trainable_variables))\n",
    "\n",
    "        self.m_disc_optimizer.apply_gradients(zip(monet_discriminator_gradients,\n",
    "                                                  self.m_disc.trainable_variables))\n",
    "\n",
    "        self.p_disc_optimizer.apply_gradients(zip(photo_discriminator_gradients,\n",
    "                                                  self.p_disc.trainable_variables))\n",
    "        \n",
    "        return {\n",
    "            \"monet_gen_loss\": total_monet_gen_loss,\n",
    "            \"photo_gen_loss\": total_photo_gen_loss,\n",
    "            \"monet_disc_loss\": monet_disc_loss,\n",
    "            \"photo_disc_loss\": photo_disc_loss\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:45:09.539150Z",
     "iopub.status.busy": "2021-12-12T23:45:09.538890Z",
     "iopub.status.idle": "2021-12-12T23:45:09.558670Z",
     "shell.execute_reply": "2021-12-12T23:45:09.557451Z",
     "shell.execute_reply.started": "2021-12-12T23:45:09.539112Z"
    }
   },
   "outputs": [],
   "source": [
    "with tpu_strategy.scope():\n",
    "    # Discriminator loss {0: fake, 1: real} (The discriminator loss outputs the average of the real and generated loss)\n",
    "    def discriminator_loss(real, generated):\n",
    "        real_loss = losses.BinaryCrossentropy(from_logits=True, reduction=losses.Reduction.NONE)(tf.ones_like(real), real)\n",
    "\n",
    "        generated_loss = losses.BinaryCrossentropy(from_logits=True, reduction=losses.Reduction.NONE)(tf.zeros_like(generated), generated)\n",
    "\n",
    "        total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "        return total_disc_loss * 0.5\n",
    "    # Generator loss\n",
    "    def generator_loss(generated):\n",
    "        return losses.BinaryCrossentropy(from_logits=True, reduction=losses.Reduction.NONE)(tf.ones_like(generated), generated)\n",
    "    \n",
    "    \n",
    "    # Cycle consistency loss (measures if original photo and the twice transformed photo to be similar to one another)\n",
    "    with tpu_strategy.scope():\n",
    "        def calc_cycle_loss(real_image, cycled_image, LAMBDA):\n",
    "            loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "\n",
    "            return LAMBDA * loss1\n",
    "\n",
    "    # Identity loss (compares the image with its generator (i.e. photo with photo generator))\n",
    "    with tpu_strategy.scope():\n",
    "        def identity_loss(real_image, same_image, LAMBDA):\n",
    "            loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "            return LAMBDA * 0.5 * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:45:09.560421Z",
     "iopub.status.busy": "2021-12-12T23:45:09.560043Z",
     "iopub.status.idle": "2021-12-12T23:45:09.572256Z",
     "shell.execute_reply": "2021-12-12T23:45:09.571453Z",
     "shell.execute_reply.started": "2021-12-12T23:45:09.560378Z"
    }
   },
   "outputs": [],
   "source": [
    "with tpu_strategy.scope():\n",
    "    monet_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    photo_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "    monet_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    photo_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:45:09.574154Z",
     "iopub.status.busy": "2021-12-12T23:45:09.573823Z",
     "iopub.status.idle": "2021-12-12T23:45:09.650220Z",
     "shell.execute_reply": "2021-12-12T23:45:09.649288Z",
     "shell.execute_reply.started": "2021-12-12T23:45:09.574114Z"
    }
   },
   "outputs": [],
   "source": [
    "with tpu_strategy.scope():\n",
    "    cycle_gan_model = CycleGan(\n",
    "        monet_generator, photo_generator, \n",
    "        monet_discriminator, photo_discriminator\n",
    "    )\n",
    "\n",
    "    cycle_gan_model.compile(\n",
    "        m_gen_optimizer = monet_generator_optimizer,\n",
    "        p_gen_optimizer = photo_generator_optimizer,\n",
    "        m_disc_optimizer = monet_discriminator_optimizer,\n",
    "        p_disc_optimizer = photo_discriminator_optimizer,\n",
    "        gen_loss_fn = generator_loss,\n",
    "        disc_loss_fn = discriminator_loss,\n",
    "        cycle_loss_fn = calc_cycle_loss,\n",
    "        identity_loss_fn = identity_loss\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T23:45:09.652116Z",
     "iopub.status.busy": "2021-12-12T23:45:09.651638Z",
     "iopub.status.idle": "2021-12-13T01:53:11.727468Z",
     "shell.execute_reply": "2021-12-13T01:53:11.726062Z",
     "shell.execute_reply.started": "2021-12-12T23:45:09.652076Z"
    }
   },
   "outputs": [],
   "source": [
    "cycle_gan_model.fit(\n",
    "    data,\n",
    "    epochs=30,\n",
    "    steps_per_epoch=(max(monet_jpg, photo_jpg)//BATCH_SIZE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T01:53:11.729665Z",
     "iopub.status.busy": "2021-12-13T01:53:11.729100Z",
     "iopub.status.idle": "2021-12-13T01:53:11.738822Z",
     "shell.execute_reply": "2021-12-13T01:53:11.737262Z",
     "shell.execute_reply.started": "2021-12-13T01:53:11.729612Z"
    }
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "def predict_and_save(input_ds, generator_model, output_path):\n",
    "    i = 1\n",
    "    for img in input_ds:\n",
    "        prediction = generator_model(img, training=False)[0].numpy() # make predition\n",
    "        prediction = (prediction * 127.5 + 127.5).astype(np.uint8)   # re-scale\n",
    "        im = PIL.Image.fromarray(prediction)\n",
    "        im.save(f'{output_path}{str(i)}.jpg')\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates the final zip folder for Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T01:53:11.741441Z",
     "iopub.status.busy": "2021-12-13T01:53:11.740937Z",
     "iopub.status.idle": "2021-12-13T02:33:23.485419Z",
     "shell.execute_reply": "2021-12-13T02:33:23.484112Z",
     "shell.execute_reply.started": "2021-12-13T01:53:11.741402Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('../images/') # Create folder to save generated images\n",
    "\n",
    "predict_and_save(load_dataset(photos_tfr).batch(1), monet_generator, '../images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T02:33:23.487852Z",
     "iopub.status.busy": "2021-12-13T02:33:23.487486Z",
     "iopub.status.idle": "2021-12-13T02:33:27.576657Z",
     "shell.execute_reply": "2021-12-13T02:33:27.575744Z",
     "shell.execute_reply.started": "2021-12-13T02:33:23.487806Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.make_archive(\"/kaggle/working/images\", 'zip', \"/kaggle/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T02:33:27.578414Z",
     "iopub.status.busy": "2021-12-13T02:33:27.578148Z",
     "iopub.status.idle": "2021-12-13T02:33:27.639180Z",
     "shell.execute_reply": "2021-12-13T02:33:27.637928Z",
     "shell.execute_reply.started": "2021-12-13T02:33:27.578388Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Number of generated samples: {len([name for name in os.listdir('../images/') if os.path.isfile(os.path.join('../images/', name))])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display Generated Samples for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T02:33:27.641040Z",
     "iopub.status.busy": "2021-12-13T02:33:27.640581Z",
     "iopub.status.idle": "2021-12-13T02:33:27.648948Z",
     "shell.execute_reply": "2021-12-13T02:33:27.647863Z",
     "shell.execute_reply.started": "2021-12-13T02:33:27.641009Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_generated_samples(ds, model, n_samples):\n",
    "    ds_iter = iter(ds)\n",
    "    for n_sample in range(n_samples):\n",
    "        example_sample = next(ds_iter)\n",
    "        generated_sample = model.predict(example_sample)\n",
    "    \n",
    "        plt.subplot(121)\n",
    "        plt.title(\"Input image\")\n",
    "        plt.imshow(example_sample[0] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(122)\n",
    "        plt.title(\"Generated image\")\n",
    "        plt.imshow(generated_sample[0] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T02:33:27.650652Z",
     "iopub.status.busy": "2021-12-13T02:33:27.650416Z",
     "iopub.status.idle": "2021-12-13T02:33:42.933272Z",
     "shell.execute_reply": "2021-12-13T02:33:42.932287Z",
     "shell.execute_reply.started": "2021-12-13T02:33:27.650627Z"
    }
   },
   "outputs": [],
   "source": [
    "display_generated_samples(load_dataset(photos_tfr).batch(1), monet_generator, 7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
