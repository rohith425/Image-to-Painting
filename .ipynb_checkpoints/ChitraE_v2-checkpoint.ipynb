{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99b65ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChitraE\n"
     ]
    }
   ],
   "source": [
    "print('ChitraE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c7f100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import LeakyReLU, BatchNormalization, ReLU, Activation\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, Concatenate, Dense, concatenate\n",
    "from tensorflow.keras.layers import Flatten, Lambda, Reshape, ZeroPadding2D, add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e4ca0b",
   "metadata": {},
   "source": [
    "# Creating the generator and discriminator for stage1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c502e797",
   "metadata": {},
   "source": [
    "## Models for conditional augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe4e50cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_aug(x):\n",
    "    print('Entering Conditiona_aug function')\n",
    "    mean = x[:, :128]\n",
    "    log_sigma = x[:, 128:]\n",
    "    stddev = K.exp(log_sigma)\n",
    "    epsilon = K.random_normal(shape=K.constant((mean.shape[1],), dtype='int32'))\n",
    "    c = stddev * epsilon + mean\n",
    "    print(\"x is:\",x)\n",
    "    print(\"mean and log_sigma are\",mean,log_sigma)\n",
    "    print('c is',c)\n",
    "    print('Exiting Conditiona_aug function')\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6a4c4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conditional_aug_model():\n",
    "    #This function returns a conditional augmentation model.\n",
    "    input_layer=Input(shape=(1024,))\n",
    "    x=Dense(256)(input_layer)\n",
    "    x=LeakyReLU(alpha=0.2)(x)\n",
    "    conditional_model=Model(inputs=[input_layer],outputs=[x])\n",
    "    return conditional_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5ddb939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1024)]            0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 262,400\n",
      "Trainable params: 262,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Cell to check above model and its summary\n",
    "dummy_conditional_model=build_conditional_aug_model()\n",
    "dummy_conditional_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14742cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another dummy cell to check the output of the model.\n",
    "dummy=np.random.randint(low=1, high=40, size=1024, dtype=int)\n",
    "# np.reshape(dummy,(1,1024))\n",
    "# out=dummy_conditional_model(dummy)\n",
    "# out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6aa399",
   "metadata": {},
   "source": [
    "## Model for compressing the embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf4b4a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embeddings_compressor_model():\n",
    "    #This will be used in the discriminator and not in the generator.\n",
    "    input_layer=Input(shape=(1024,))\n",
    "    x=Dense(128)(input_layer)\n",
    "    x=ReLU()(x)\n",
    "    \n",
    "    compressor_model=Model(inputs=[input_layer],outputs=[x])\n",
    "    return compressor_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9cc284c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 1024)]            0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               131200    \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 128)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 131,200\n",
      "Trainable params: 131,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Cell to check summary of the compressor model\n",
    "dummy_compressor_model=build_embeddings_compressor_model().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d2a53d",
   "metadata": {},
   "source": [
    "# Stage 1 Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "549512ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stage1_generator():\n",
    "    input_layer1 = Input(shape=(1024,))\n",
    "    x = Dense(256)(input_layer1)\n",
    "    mean_logsigma = LeakyReLU(alpha=0.2)(x)\n",
    "    c = Lambda(conditional_aug)(mean_logsigma)\n",
    "\n",
    "    input_layer2 = Input(shape=(100,))\n",
    "\n",
    "    gen_input = Concatenate(axis=1)([c, input_layer2])\n",
    "\n",
    "    x = Dense(128 * 8 * 4 * 4, use_bias=False)(gen_input)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Reshape((4, 4, 128 * 8), input_shape=(128 * 8 * 4 * 4,))(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(512, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(128, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(64, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2D(3, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = Activation(activation='tanh')(x)\n",
    "\n",
    "    stage1_gen = Model(inputs=[input_layer1, input_layer2], outputs=[x, mean_logsigma])\n",
    "    return stage1_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bcc165a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Conditiona_aug function\n",
      "x is: Tensor(\"Placeholder:0\", shape=(None, 256), dtype=float32)\n",
      "mean and log_sigma are Tensor(\"lambda_2/strided_slice:0\", shape=(None, 128), dtype=float32) Tensor(\"lambda_2/strided_slice_1:0\", shape=(None, 128), dtype=float32)\n",
      "c is Tensor(\"lambda_2/add:0\", shape=(None, 128), dtype=float32)\n",
      "Exiting Conditiona_aug function\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 1024)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 256)          262400      ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 256)          0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, 128)          0           ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 228)          0           ['lambda_2[0][0]',               \n",
      "                                                                  'input_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 16384)        3735552     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 16384)        0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 4, 4, 1024)   0           ['re_lu_7[0][0]']                \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 8, 8, 1024)  0           ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 8, 8, 512)    4718592     ['up_sampling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 8, 8, 512)   2048        ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 8, 8, 512)    0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 16, 16, 512)  0          ['re_lu_8[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 16, 256)  1179648     ['up_sampling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)                 (None, 16, 16, 256)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSampling2D)  (None, 32, 32, 256)  0          ['re_lu_9[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 128)  294912      ['up_sampling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)                (None, 32, 32, 128)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_7 (UpSampling2D)  (None, 64, 64, 128)  0          ['re_lu_10[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 64, 64, 64)   73728       ['up_sampling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)                (None, 64, 64, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 64, 64, 3)    1728        ['re_lu_11[0][0]']               \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 64, 64, 3)    0           ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,270,400\n",
      "Trainable params: 10,268,480\n",
      "Non-trainable params: 1,920\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Cell to check the summary of stage1 Generator:\n",
    "dummy_stage1_generator=build_stage1_generator()\n",
    "dummy_stage1_generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e237ce44",
   "metadata": {},
   "source": [
    "## Stage 1 discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d544914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stage1_discriminator():\n",
    "    input_layer = Input(shape=(64, 64, 3))\n",
    "\n",
    "    x = Conv2D(64, (4, 4),padding='same', strides=2,input_shape=(64, 64, 3), use_bias=False)(input_layer)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(128, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(256, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(512, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    input_layer2 = Input(shape=(4, 4, 128))\n",
    "\n",
    "    merged_input = concatenate([x, input_layer2])\n",
    "\n",
    "    x2 = Conv2D(64 * 8, kernel_size=1,padding=\"same\", strides=1)(merged_input)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = LeakyReLU(alpha=0.2)(x2)\n",
    "    x2 = Flatten()(x2)\n",
    "    x2 = Dense(1)(x2)\n",
    "    x2 = Activation('sigmoid')(x2)\n",
    "\n",
    "    stage1_dis = Model(inputs=[input_layer, input_layer2], outputs=[x2])\n",
    "    return stage1_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "151b83fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 64, 64, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 32, 32, 64)   3072        ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 32, 32, 64)   0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 16, 16, 128)  131072      ['leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_11[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 16, 16, 128)  0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 8, 8, 256)    524288      ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_12[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 8, 8, 256)    0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 4, 4, 512)    2097152     ['leaky_re_lu_9[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 4, 4, 512)    0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)          [(None, 4, 4, 128)]  0           []                               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 4, 4, 640)    0           ['leaky_re_lu_10[0][0]',         \n",
      "                                                                  'input_14[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 4, 4, 512)    328192      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 4, 4, 512)    0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 8192)         0           ['leaky_re_lu_11[0][0]']         \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 1)            8193        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 1)            0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,097,601\n",
      "Trainable params: 3,094,785\n",
      "Non-trainable params: 2,816\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Cell to check summary of discriminator\n",
    "dummy_stage1_discriminator=build_stage1_discriminator()\n",
    "dummy_stage1_discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2331ef",
   "metadata": {},
   "source": [
    "## Building the stage1 GAN( combining generator and discriminator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e1f5d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adversarial_model(generator,discriminator):\n",
    "    input_layer1=Input(shape=(1024,))\n",
    "    input_layer2=Input(shape=(100,))\n",
    "    input_layer3=Input(shape=(4,4,128))\n",
    "    \n",
    "    x, mean_logsigma = generator([input_layer1, input_layer2])\n",
    "    discriminator.trainable = False\n",
    "    valid = discriminator([x, input_layer3])\n",
    "\n",
    "    model = Model(inputs=[input_layer1, input_layer2, input_layer3], outputs=[valid, mean_logsigma])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "692cdf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Conditiona_aug function\n",
      "x is: Tensor(\"model_6/leaky_re_lu_6/LeakyRelu:0\", shape=(None, 256), dtype=float32)\n",
      "mean and log_sigma are Tensor(\"model_6/lambda_2/strided_slice:0\", shape=(None, 128), dtype=float32) Tensor(\"model_6/lambda_2/strided_slice_1:0\", shape=(None, 128), dtype=float32)\n",
      "c is Tensor(\"model_6/lambda_2/add:0\", shape=(None, 128), dtype=float32)\n",
      "Exiting Conditiona_aug function\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_21 (InputLayer)          [(None, 1024)]       0           []                               \n",
      "                                                                                                  \n",
      " input_22 (InputLayer)          [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " model_6 (Functional)           [(None, 64, 64, 3),  10270400    ['input_21[0][0]',               \n",
      "                                 (None, 256)]                     'input_22[0][0]']               \n",
      "                                                                                                  \n",
      " input_23 (InputLayer)          [(None, 4, 4, 128)]  0           []                               \n",
      "                                                                                                  \n",
      " model_7 (Functional)           (None, 1)            3097601     ['model_6[1][0]',                \n",
      "                                                                  'input_23[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,368,001\n",
      "Trainable params: 10,268,480\n",
      "Non-trainable params: 3,099,521\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Cell to check summary of entire stage 1 GAN:\n",
    "stage1_gan=build_adversarial_model(dummy_stage1_generator,dummy_stage1_discriminator)\n",
    "stage1_gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be09d710",
   "metadata": {},
   "source": [
    "# Code for Loading the files from dataset required for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "26349de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_class_ids(class_info_file_path):\n",
    "    with open(class_info_file_path, 'rb') as f:\n",
    "        class_ids = pickle.load(f, encoding='latin1')\n",
    "        return class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b58fe8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(embeddings_file_path):\n",
    "    with open(embeddings_file_path, 'rb') as f:\n",
    "        embeddings = pickle.load(f, encoding='latin1')\n",
    "        embeddings = np.array(embeddings)\n",
    "        print('embeddings: ', embeddings.shape)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8e9d006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filenames(filenames_file_path):\n",
    "    with open(filenames_file_path, 'rb') as f:\n",
    "        filenames = pickle.load(f, encoding='latin1')\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "242f644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bounding_boxes(dataset_dir):\n",
    "    # Paths\n",
    "    bounding_boxes_path = os.path.join(dataset_dir, 'bounding_boxes.txt')\n",
    "    file_paths_path = os.path.join(dataset_dir, 'images.txt')\n",
    "\n",
    "    # Read bounding_boxes.txt and images.txt file\n",
    "    df_bounding_boxes = pd.read_csv(bounding_boxes_path,\n",
    "                                    delim_whitespace=True, header=None).astype(int)\n",
    "    df_file_names = pd.read_csv(file_paths_path, delim_whitespace=True, header=None)\n",
    "\n",
    "    # Create a list of file names\n",
    "    file_names = df_file_names[1].tolist()\n",
    "\n",
    "    # Create a dictionary of file_names and bounding boxes\n",
    "    filename_boundingbox_dict = {img_file[:-4]: [] for img_file in file_names[:2]}\n",
    "\n",
    "    # Assign a bounding box to the corresponding image\n",
    "    for i in range(0, len(file_names)):\n",
    "        # Get the bounding box\n",
    "        bounding_box = df_bounding_boxes.iloc[i][1:].tolist()\n",
    "        key = file_names[i][:-4]\n",
    "        filename_boundingbox_dict[key] = bounding_box\n",
    "\n",
    "    return filename_boundingbox_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6bce73ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(img_path, bbox, image_size):\n",
    "    \"\"\"\n",
    "    Load and resize image\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    width, height = img.size\n",
    "    if bbox is not None:\n",
    "        R = int(np.maximum(bbox[2], bbox[3]) * 0.75)\n",
    "        center_x = int((2 * bbox[0] + bbox[2]) / 2)\n",
    "        center_y = int((2 * bbox[1] + bbox[3]) / 2)\n",
    "        y1 = np.maximum(0, center_y - R)\n",
    "        y2 = np.minimum(height, center_y + R)\n",
    "        x1 = np.maximum(0, center_x - R)\n",
    "        x2 = np.minimum(width, center_x + R)\n",
    "        img = img.crop([x1, y1, x2, y2])\n",
    "    img = img.resize(image_size, PIL.Image.BILINEAR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1d86a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filenames_file_path, class_info_file_path, cub_dataset_dir, embeddings_file_path, image_size):\n",
    "    \"\"\"\n",
    "    Load dataset\n",
    "    \"\"\"\n",
    "    filenames = load_filenames(filenames_file_path)\n",
    "    class_ids = load_class_ids(class_info_file_path)\n",
    "    bounding_boxes = load_bounding_boxes(cub_dataset_dir)\n",
    "    all_embeddings = load_embeddings(embeddings_file_path)\n",
    "\n",
    "    X, y, embeddings = [], [], []\n",
    "\n",
    "    print(\"Embeddings shape:\", all_embeddings.shape)\n",
    "\n",
    "    for index, filename in enumerate(filenames):\n",
    "        bounding_box = bounding_boxes[filename]\n",
    "\n",
    "        try:\n",
    "            # Load images\n",
    "            img_name = '{}/images/{}.jpg'.format(cub_dataset_dir, filename)\n",
    "            img = get_img(img_name, bounding_box, image_size)\n",
    "\n",
    "            all_embeddings1 = all_embeddings[index, :, :]\n",
    "\n",
    "            embedding_ix = random.randint(0, all_embeddings1.shape[0] - 1)\n",
    "            embedding = all_embeddings1[embedding_ix, :]\n",
    "\n",
    "            X.append(np.array(img))\n",
    "            y.append(class_ids[index])\n",
    "            embeddings.append(embedding)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    embeddings = np.array(embeddings)\n",
    "    return X, y, embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d751b4",
   "metadata": {},
   "source": [
    "# Calculating loss and saving images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3bf6e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_loss(y_true, y_pred):\n",
    "    mean = y_pred[:, :128]\n",
    "    logsigma = y_pred[:, :128]\n",
    "    loss = -logsigma + .5 * (-1 + K.exp(2. * logsigma) + K.square(mean))\n",
    "    loss = K.mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "98bdf9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_generator_loss(y_true, y_pred):\n",
    "    # Calculate binary cross entropy loss\n",
    "    return K.binary_crossentropy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "10318070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_rgb_img(img, path):\n",
    "    \"\"\"\n",
    "    Save an rgb image\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(\"Image\")\n",
    "\n",
    "    plt.savefig(path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "81f59d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_log(callback, name, loss, batch_no):\n",
    "    \"\"\"\n",
    "    Write training summary to TensorBoard\n",
    "    \"\"\"\n",
    "    summary = tf.Summary()\n",
    "    summary_value = summary.value.add()\n",
    "    summary_value.simple_value = loss\n",
    "    summary_value.tag = name\n",
    "    callback.writer.add_summary(summary, batch_no)\n",
    "    callback.writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ca06a5",
   "metadata": {},
   "source": [
    "# Building the actual model. Compiling it and training it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c9f69873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aneesh Kulkarni\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/birds//train/filenames.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ANEESH~1\\AppData\\Local\\Temp/ipykernel_3168/3139968342.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mLoad\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \"\"\"\n\u001b[1;32m---> 32\u001b[1;33m     X_train, y_train, embeddings_train = load_dataset(filenames_file_path=filenames_file_path_train,\n\u001b[0m\u001b[0;32m     33\u001b[0m                                                       \u001b[0mclass_info_file_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_info_file_path_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                                                       \u001b[0mcub_dataset_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcub_dataset_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ANEESH~1\\AppData\\Local\\Temp/ipykernel_3168/3390863186.py\u001b[0m in \u001b[0;36mload_dataset\u001b[1;34m(filenames_file_path, class_info_file_path, cub_dataset_dir, embeddings_file_path, image_size)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mLoad\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mfilenames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_filenames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mclass_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_class_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_info_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mbounding_boxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_bounding_boxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcub_dataset_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ANEESH~1\\AppData\\Local\\Temp/ipykernel_3168/724894515.py\u001b[0m in \u001b[0;36mload_filenames\u001b[1;34m(filenames_file_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_filenames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mfilenames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/birds//train/filenames.pickle'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    data_dir = \"/content/birds/\"\n",
    "    train_dir = data_dir + \"/train\"\n",
    "    test_dir = data_dir + \"/test\"\n",
    "    image_size = 64\n",
    "    batch_size = 64\n",
    "    z_dim = 100\n",
    "    stage1_generator_lr = 0.0002\n",
    "    stage1_discriminator_lr = 0.0002\n",
    "    stage1_lr_decay_step = 600\n",
    "    epochs = 1000\n",
    "    condition_dim = 128\n",
    "\n",
    "    embeddings_file_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "    embeddings_file_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "\n",
    "    filenames_file_path_train = train_dir + \"/filenames.pickle\"\n",
    "    filenames_file_path_test = test_dir + \"/filenames.pickle\"\n",
    "\n",
    "    class_info_file_path_train = train_dir + \"/class_info.pickle\"\n",
    "    class_info_file_path_test = test_dir + \"/class_info.pickle\"\n",
    "\n",
    "    cub_dataset_dir = \"/content/CUB_200_2011\"\n",
    "    \n",
    "    # Define optimizers\n",
    "    dis_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
    "    gen_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n",
    "\n",
    "    \"\"\"\"\n",
    "    Load datasets\n",
    "    \"\"\"\n",
    "    X_train, y_train, embeddings_train = load_dataset(filenames_file_path=filenames_file_path_train,\n",
    "                                                      class_info_file_path=class_info_file_path_train,\n",
    "                                                      cub_dataset_dir=cub_dataset_dir,\n",
    "                                                      embeddings_file_path=embeddings_file_path_train,\n",
    "                                                      image_size=(64, 64))\n",
    "\n",
    "    X_test, y_test, embeddings_test = load_dataset(filenames_file_path=filenames_file_path_test,\n",
    "                                                   class_info_file_path=class_info_file_path_test,\n",
    "                                                   cub_dataset_dir=cub_dataset_dir,\n",
    "                                                   embeddings_file_path=embeddings_file_path_test,\n",
    "                                                   image_size=(64, 64))\n",
    "\n",
    "    \"\"\"\n",
    "    Build and compile networks\n",
    "    \"\"\"\n",
    "    ca_model = build_ca_model()\n",
    "    ca_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "    stage1_dis = build_stage1_discriminator()\n",
    "    stage1_dis.compile(loss='binary_crossentropy', optimizer=dis_optimizer)\n",
    "\n",
    "    stage1_gen = build_stage1_generator()\n",
    "    stage1_gen.compile(loss=\"mse\", optimizer=gen_optimizer)\n",
    "\n",
    "    embedding_compressor_model = build_embedding_compressor_model()\n",
    "    embedding_compressor_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "    adversarial_model = build_adversarial_model(gen_model=stage1_gen, dis_model=stage1_dis)\n",
    "    adversarial_model.compile(loss=['binary_crossentropy', KL_loss], loss_weights=[1, 2.0],\n",
    "                              optimizer=gen_optimizer, metrics=None)\n",
    "\n",
    "    tensorboard = TensorBoard(log_dir=\"logs/\".format(time.time()))\n",
    "    tensorboard.set_model(stage1_gen)\n",
    "    tensorboard.set_model(stage1_dis)\n",
    "    tensorboard.set_model(ca_model)\n",
    "    tensorboard.set_model(embedding_compressor_model)\n",
    "\n",
    "    # Generate an array containing real and fake values\n",
    "    # Apply label smoothing as well\n",
    "    real_labels = np.ones((batch_size, 1), dtype=float) * 0.9\n",
    "    fake_labels = np.zeros((batch_size, 1), dtype=float) * 0.1\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(\"========================================\")\n",
    "        print(\"Epoch is:\", epoch)\n",
    "        print(\"Number of batches\", int(X_train.shape[0] / batch_size))\n",
    "\n",
    "        gen_losses = []\n",
    "        dis_losses = []\n",
    "\n",
    "        # Load data and train model\n",
    "        number_of_batches = int(X_train.shape[0] / batch_size)\n",
    "        for index in range(number_of_batches):\n",
    "            print(\"Batch:{}\".format(index+1))\n",
    "            \n",
    "            \"\"\"\n",
    "            Train the discriminator network\n",
    "            \"\"\"\n",
    "            # Sample a batch of data\n",
    "            z_noise = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
    "            image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "            embedding_batch = embeddings_train[index * batch_size:(index + 1) * batch_size]\n",
    "            image_batch = (image_batch - 127.5) / 127.5\n",
    "\n",
    "            # Generate fake images\n",
    "            fake_images, _ = stage1_gen.predict([embedding_batch, z_noise], verbose=3)\n",
    "\n",
    "            # Generate compressed embeddings\n",
    "            compressed_embedding = embedding_compressor_model.predict_on_batch(embedding_batch)\n",
    "            compressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, condition_dim))\n",
    "            compressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n",
    "\n",
    "            dis_loss_real = stage1_dis.train_on_batch([image_batch, compressed_embedding],\n",
    "                                                      np.reshape(real_labels, (batch_size, 1)))\n",
    "            dis_loss_fake = stage1_dis.train_on_batch([fake_images, compressed_embedding],\n",
    "                                                      np.reshape(fake_labels, (batch_size, 1)))\n",
    "            dis_loss_wrong = stage1_dis.train_on_batch([image_batch[:(batch_size - 1)], compressed_embedding[1:]],\n",
    "                                                       np.reshape(fake_labels[1:], (batch_size-1, 1)))\n",
    "\n",
    "            d_loss = 0.5 * np.add(dis_loss_real, 0.5 * np.add(dis_loss_wrong, dis_loss_fake))\n",
    "\n",
    "            print(\"d_loss_real:{}\".format(dis_loss_real))\n",
    "            print(\"d_loss_fake:{}\".format(dis_loss_fake))\n",
    "            print(\"d_loss_wrong:{}\".format(dis_loss_wrong))\n",
    "            print(\"d_loss:{}\".format(d_loss))\n",
    "\n",
    "            \"\"\"\n",
    "            Train the generator network \n",
    "            \"\"\"\n",
    "            g_loss = adversarial_model.train_on_batch([embedding_batch, z_noise, compressed_embedding],[K.ones((batch_size, 1)) * 0.9, K.ones((batch_size, 256)) * 0.9])\n",
    "            print(\"g_loss:{}\".format(g_loss))\n",
    "\n",
    "            dis_losses.append(d_loss)\n",
    "            gen_losses.append(g_loss)\n",
    "\n",
    "        \"\"\"\n",
    "        Save losses to Tensorboard after each epoch\n",
    "        \"\"\"\n",
    "        write_log(tensorboard, 'discriminator_loss', np.mean(dis_losses), epoch)\n",
    "        write_log(tensorboard, 'generator_loss', np.mean(gen_losses[0]), epoch)\n",
    "        \n",
    "        # Generate and save images after every 2nd epoch\n",
    "        if epoch % 2 == 0:\n",
    "            # z_noise2 = np.random.uniform(-1, 1, size=(batch_size, z_dim))\n",
    "            z_noise2 = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
    "            embedding_batch = embeddings_test[0:batch_size]\n",
    "            fake_images, _ = stage1_gen.predict_on_batch([embedding_batch, z_noise2])\n",
    "\n",
    "            # Save images\n",
    "            for i, img in enumerate(fake_images[:10]):\n",
    "                save_rgb_img(img, \"results/gen_{}_{}.png\".format(epoch, i))\n",
    "\n",
    "    # Save models\n",
    "    stage1_gen.save_weights(\"stage1_gen.h5\")\n",
    "    stage1_dis.save_weights(\"stage1_dis.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08e799d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
